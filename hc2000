#!/usr/bin/python

import argparse
import boto.ec2
import boto.ec2.autoscale
import boto.ec2.blockdevicemapping
import email.mime.base
import email.mime.multipart
import os
import os.path
import sys
import yaml
import hc2002.aws.iam
import hc2002.aws.ec2
import hc2002.aws.auto_scaling
import hc2002.config
import hc2002.manifest
import hc2002.resource.instance
import hc2002.resource.load_balancer
import hc2002.resource.role
import hc2002.transform as xf
import hc2002.translation as xl
import hc2002.validation

def _load_definition(filename):
    try:
        with open(filename) as f:
            sys.stdout.write('Loading %s...' % filename)
            sys.stdout.flush()

            definition = yaml.safe_load(f)

        sys.stdout.write(' [ OK ]\n')
        return definition

    except IOError as err:
        pass

def _merge_definition(definition, new):
    if new is not None:
        definition.update(new)

# xl for translate, xf for transform.
def _apply_mapping(mapping, result, value):
    if hasattr(mapping, '__iter__'):
        for m in mapping:
            _apply_mapping(m, result, value)
    else:
        mapping(result, value)

_resolvable_prefixes = ('image:', 'kernel:', 'key:', 'load-balancers:',
    'ramdisk:', 'security-groups:', 'spot-price:', 'subnet:')

ec2_block_device_mapping = {
    'source':       xl.switch({
                        'no-device':            xl.set_value('no_device', True),
                        'ephemeral[0-9]':       xl.set_key('ephemeral_name'),
                        'snap-[a-fA-F0-9]*':    xl.set_key('snapshot_id'),
                    }),
    'size':         xl.set_key('size'),
    'iops':         [
                        xl.set_key('iops'),
                        xl.set_value('volume_type', 'io1')
                    ],
    'disposable':   xl.set_key('delete_on_termination'),
}

# For BlockDeviceMappings in LaunchConfigurations, use AWS parameter names
# directly to work around boto bug
as_block_device_mapping = {
    'source':       xl.switch({
                        'ephemeral[0-9]':       xl.set_key('VirtualName'),
                        'snap-[a-fA-F0-9]*':    xl.set_key('Ebs.SnapshotId'),
                    }),
    'size':         xl.set_key('Ebs.VolumeSize'),
}

def _xl_ec2_block_devices(key):
    def _block_devices(destination, value):
        bdm = boto.ec2.blockdevicemapping.BlockDeviceMapping()
        for k, v in value.iteritems():
            params = xl.translate(ec2_block_device_mapping, v,
                    { 'delete_on_termination': True })
            bdm[k] = boto.ec2.blockdevicemapping.BlockDeviceType(**params)
        destination[key] = bdm

    return _block_devices

def _xl_as_block_devices(key):
    def _block_devices(destination, value):
        mappings = []
        for k, v in value.iteritems():
            # boto.ec2.autoscale.launchconfig.BlockDeviceMapping does not get
            # properly propagated to API call
            bdm = xl.translate(as_block_device_mapping, v)
            bdm['DeviceName'] = k
            mappings.append(bdm)
        destination[key] = mappings

    return _block_devices

_magic_to_mime = {
    '#!':               ('text', 'x-shellscript'),
    '#cloud-boothook':  ('text', 'cloud-boothook'),
    '#cloud-config':    ('text', 'cloud-config'),
    '#include':         ('text', 'x-include-url'),
    '#manifest':        ('text', 'hc2000-manifest'),
    '#part-handler':    ('text', 'part-handler'),
    '#puppet':          ('text', 'puppet'),
    '#upstart-job':     ('text', 'upstart-job'),
}

def _xl_user_data(key):
    def _user_data_file(filename):
        with open(filename, 'rb') as f:
            filename = os.path.basename(filename)
            return _user_data_entry(f.read(), filename)

    def _user_data_entry(value, filename=None):
        if value.startswith('file:'):
            return _user_data_file(value[5:])

        maintype, subtype = ('application', 'octet-stream')
        for magic, mime in _magic_to_mime.iteritems():
            if value.startswith(magic):
                maintype, subtype = mime
                break
        if maintype == 'text':
            msg = email.mime.text.MIMEText(value, subtype)
        else:
            msg = email.mime.base.MIMEBase(maintype, subtype)
            msg.set_payload(value)
        if filename:
            msg.add_header('Content-Disposition', 'attachment', filename=filename)
        else:
            msg.add_header('Content-Disposition', 'attachment')
        return msg

    def _user_data(destination, value):
        if isinstance(value, basestring) \
                or not hasattr(value, '__iter__'):
            destination[key] = value
            return

        data = email.mime.multipart.MIMEMultipart()
        for d in value:
            data.attach(_user_data_entry(d))
        destination[key] = data.as_string()

    return _user_data

# boto.ec2.autoscale.Tag unconditionally outputs optional parameters ResourceId
# and ResourceType, requiring them to be set. _Tag works around that
# constraint.
class _Tag:
    def __init__(self, key, value):
        self.key = key
        self.value = value

    def build_params(self, params, i):
        prefix = 'Tags.member.%d.' % i
        params[prefix + 'Key'] = self.key
        params[prefix + 'Value'] = self.value

def _xl_as_tags(destination, value):
    tags = []
    for k, v in value.iteritems():
        tags.append(_Tag(k, v))
    destination['tags'] = tags

run_instances_mapping = {
    'instance-type':        xl.set_key('instance_type'),
    'ebs-optimized':        xl.set_key('ebs_optimized'),
    'block-devices':        _xl_ec2_block_devices('block_device_map'),
    'image':                xl.set_key('image_id'),
    'kernel':               xl.set_key('kernel_id'),
    'ramdisk':              xl.set_key('ramdisk_id'),
    'min-count':            xl.set_key('min_count'),
    'max-count':            xl.set_key('max_count'),
    'count':                xl.set_key('max_count'),
    'tags':                 xl.ignore,
    'key':                  xl.set_key('key_name'),
    'role':                 xl.if_(xf.match('arn:aws:iam::'),
                                xl.set_key('instance_profile_arn'),
                                xl.set_key('instance_profile_name')),
    'security-groups':      xl.for_each(
                                xl.if_(xf.match('sg-[0-9A-Fa-f]+$'),
                                    xl.append_to('security_group_ids'),
                                    xl.append_to('security_groups'))),
    'subnet':               xl.set_key('subnet_id'),
    'ip-address':           xl.set_key('private_ip_address'),
    'availability-zone':    xl.set_key('placement'),
    'placement-group':      xl.set_key('placement_group'),
    'tenancy':              xl.set_key('tenancy'),
    'user-data':            _xl_user_data('user_data'),
    'monitoring':           xl.set_key('monitoring_enabled'),
    'api-termination':      xl.set_key('disable_api_termination', lambda x: not x),
    'shutdown-behavior':    xl.set_key('instance_initiated_shutdown_behavior'),
    'client-token':         xl.set_key('client_token'),
}

spot_request_mapping = run_instances_mapping.copy()
# RunInstance arguments not supported in SpotRequests
for key in [ 'min-count', 'max-count', 'tags', 'ip-address', 'tenancy',
        'api-termination', 'shutdown-behavior', 'client-token' ]:
    del spot_request_mapping[key]
# Configuration specific to SpotRequests
spot_request_mapping.update({
    'spot-price':               xl.set_key('price'),
    'spot-request-type':        xl.set_key('type'),
    'valid-from':               xl.set_key('valid_from'),
    'valid-until':              xl.set_key('valid_until'),
    'launch-group':             xl.set_key('launch_group'),
    'availability-zone-group':  xl.set_key('availability_zone_group'),
})

launch_configuration_mapping = {
    'launch-configuration':     xl.set_key('name'),
    'instance-type':            xl.set_key('instance_type'),
    'spot-price':               xl.set_key('spot_price'),
    'image':                    xl.set_key('image_id'),
    'kernel':                   xl.set_key('kern_id'),
    'ramdisk':                  xl.set_key('ramdisk_id'),
    'key':                      xl.set_key('key_name'),
    'role':                     xl.set_key('instance_profile_name'),
    'security-groups':          xl.for_each(xl.append_to('security_groups')),
    'user-data':                _xl_user_data('user_data'),
    'monitoring':               xl.set_key('instance_monitoring'),
    'ebs-optimized':            xl.set_key('ebs_optimized'),
    'block-devices':            _xl_as_block_devices('block_device_mappings'),
}

auto_scaling_group_mapping = {
    'auto-scaling-group':           xl.set_key('name'),
    'launch-configuration':         xl.set_key('launch_config'),
    'count':                        xl.set_key('desired_capacity'),
    'min-count':                    xl.set_key('min_size'),
    'max-count':                    xl.set_key('max_size'),
    'subnet':                       xl.join('vpc_zone_identifier'),
    'availability-zone':            xl.for_each(xl.append_to('availability_zones')),
    'auto-scaling-cooldown':        xl.set_key('default_cooldown'),
    'auto-scaling-grace-period':    xl.set_key('health_check_period'),
    'auto-scaling-health-check':    xl.set_key('health_check_type'),
    'load-balancers':               xl.for_each(xl.append_to('load_balancers')),
    'tags':                         _xl_as_tags,
    'termination-policies':         xl.for_each(xl.append_to('termination_policies')),
    'schedule':                     xl.ignore,
}

# Launch Configurations and Auto-Scaling Groups are meant to share
# configuration, so have them ignore each other's keys.
launch_configuration_keys = launch_configuration_mapping.keys()
auto_scaling_group_keys = auto_scaling_group_mapping.keys()

for key in auto_scaling_group_keys:
    if key not in launch_configuration_mapping:
        launch_configuration_mapping[key] = xl.ignore
for key in launch_configuration_keys:
    if key not in auto_scaling_group_mapping:
        auto_scaling_group_mapping[key] = xl.ignore

    # TODO: NetworkInterface

def _resolve_symbolic_values(definition):
    def _resolve_symbol(value):
        visited = set()
        while isinstance(value, basestring) \
                and value.startswith(prefix):
            value = value.format(**definition)
            if value in definition \
                    and value not in visited:
                visited.add(value)
                value = definition[value]
        return value

    for prefix in _resolvable_prefixes:
        key = prefix[:-1]
        if key not in definition:
            continue

        if isinstance(definition[key], basestring):
            definition[key] = _resolve_symbol(definition[key])
        elif isinstance(definition[key], list):
            definition[key] = [ _resolve_symbol(v) for v in definition[key] ]

def load_instance_definition(config):
    instance = {}
    for path in config.instance_path:
        path = path.format(region=config.region)
        _merge_definition(instance,
                _load_definition(os.path.join(path, '~default~')))
        _merge_definition(instance,
                _load_definition(os.path.join(path, config.instance)))
    _resolve_symbolic_values(instance)
    return instance

class BootstrapActor:
    def __call__(self, config):
        self.config = config
        self.common_definitions = {}

        self.ec2 = hc2002.aws.ec2.get_connection()

        self.create_key()
        self.create_default_security_group()

        self.write_common_configuration()

    def _get_path(self, path):
        path = path.format(region=self.config.region)
        return os.path.join(self.config.path, path)

    def create_key(self):
        identities = self._get_path('identities')
        if not os.path.isdir(identities):
            os.makedirs(identities, 0700)

        key = self.ec2.get_key_pair(self.config.key)
        if key is None:
            key = self.ec2.create_key_pair(self.config.key)
            key.save(self._get_path('identities'))
            print 'Identity file for %s key saved in %s' \
                    % (self.config.key, identities)
        else:
            print 'Key %s already exists.' % self.config.key

        self.common_definitions['key:default'] = self.config.key

    def create_default_security_group(self):
        groups = self.ec2.get_all_security_groups(
                # Specifying group name as a filter avoids an exception being
                # thrown when the group doesn't exist
                filters={ 'group-name': self.config.security_group })
        if len(groups) == 0:
            print self.ec2.create_security_group(self.config.security_group,
                    'Default security group set up by hc2000 bootstrap. This '
                    'allows incoming SSH connections into instances.')
            if not self.ec2.authorize_security_group(
                    self.config.security_group, ip_protocol='tcp',
                    from_port=22, to_port=22, cidr_ip='0.0.0.0/0'):
                sys.stderr.write('Failed to open SSH port for incoming '
                        'connections security group!\n')
        else:
            print 'Security group %s already exists.' \
                    % self.config.security_group

        self.common_definitions['security-groups:default'] = \
                self.config.security_group

    def write_common_configuration(self):
        with open(self._get_path('~default~'), 'wb') as f:
            f.write(yaml.dump(self.common_definitions,
                default_flow_style=False))

def create_role_action(config):
    role = _load_definition(config.role)
    hc2002.resource.role.create(role)

_handlers_path = None

def _get_handlers_path():
    global _handlers_path
    if not _handlers_path:
        path = os.path.dirname(__file__)
        print "Path:", path
        path = os.path.abspath(path)
        print "Path:", path
        _handlers_path = os.path.join(path, 'handlers/')
        print "Handlers path:", _handlers_path
    return _handlers_path

def _user_data_extension(instance, tag, translator):
    if tag not in instance:
        return

    handler_path = os.path.join(_get_handlers_path(), tag + '.py')
    with open(handler_path, 'rb') as f:
        part_handler = f.read()
    if not part_handler.startswith('#part-handler'):
        part_handler = '#part-handler\n' + part_handler

    if 'user-data' not in instance:
        instance['user-data'] = []
    elif isinstance(instance['user-data'], basestring):
        instance['user-data'] = [ instance['user-data'] ]

    instance['user-data'].append(part_handler)
    translator(instance, instance.pop(tag))

def validate(validator, data, scope=None):
    ctx = hc2002.validation.validate(validator, data, scope)
    for scope, msg in ctx.errors:
        sys.stderr.write('%s: %s\n' % (scope, msg))
    return len(ctx.errors) == 0

def launch_action(config):
    instance = load_instance_definition(config)

    def command_line_override(option, key):
        if hasattr(config, option):
            instance[key] = getattr(config, option)

    command_line_override('client_token', 'client-token')
    command_line_override('instance_count', 'count')
    command_line_override('subnet', 'subnet')
    command_line_override('availability_zone', 'availability-zone')

    # FIXME: This should live as some sort of external plugin.
    def _include_puppet(destination, value):
        orig_value = value
        if not value.endswith('.pp'):
            value = value + '.pp'
        found = False
        for path in config.puppet_path:
            path = os.path.join(path, value)
            if os.path.exists(path):
                destination['user-data'].append('file:' + path)
                found = True
        if not found:
            print 'Couldn\'t find manifest for \'%s\'' % orig_value

    _user_data_extension(instance, 'puppet', xl.for_each(_include_puppet))

    def _xf_manifest(value):
        if not isinstance(value, basestring):
            value = yaml.dump(value)
        if not value.startswith(('file:', '#manifest\n')):
            value = '#manifest\n' + value
        return value

    _user_data_extension(instance, 'manifest',
            xl.for_each(xl.append_to('user-data', _xf_manifest)))

    if 'user-data' in instance and \
            isinstance(instance['user-data'], list):
        for i, entry in enumerate(instance['user-data']):
            if not isinstance(entry, basestring):
                continue

            scope = 'user-data[%i]' % i

            #FIXME: Should either move file inlining earlier of validation
            #       later. Should NOT read the file twice.
            if entry.startswith('file:'):
                scope += ':%s:' % entry[5:]
                entry = open(entry[5:], 'rb').read()

            if entry.startswith('#manifest'):
                print "Validating manifest:\n", entry
                validate(hc2002.manifest, yaml.safe_load(entry), scope) \
                        or sys.exit(1)

    validate(hc2002.resource.instance, instance, 'instance') \
            or sys.exit(1)

    if 'auto-scaling-group' in instance:
        _do_auto_scaling(config, instance)
    elif 'spot-price' in instance:
        _do_spot_request(config, instance)
    else:
        _do_run_instance(config, instance)

def _do_run_instance(config, definition):
    ec2 = hc2002.aws.ec2.get_connection()

    params = xl.translate(run_instances_mapping, definition)
    reservation = ec2.run_instances(**params)

    print reservation

    if 'tags' in definition:
        ec2.create_tags(
                [ instance.id for instance in reservation.instances ],
                definition['tags'])

    print reservation.instances

def _do_spot_request(config, definition):
    ec2 = hc2002.aws.ec2.get_connection()

    params = xl.translate(spot_request_mapping, definition)
    print ec2.request_spot_instances(**params)

scheduled_auto_scaling_action = {
    'count':        xl.set_key('DesiredCapacity'),
    'min-count':    xl.set_key('MinSize'),
    'max-count':    xl.set_key('MaxSize'),
    'start-time':   xl.set_key('StartTime'),
    'end-time':     xl.set_key('EndTime'),
    'recurrence':   xl.set_key('Recurrence'),
}

def _do_auto_scaling(config, definition):
    autoscale = hc2002.aws.auto_scaling.get_connection()

    launcher = autoscale.get_all_launch_configurations(names=[ definition['launch-configuration'] ])
    if len(launcher) == 0:
        params = xl.translate(launch_configuration_mapping, definition)
        print "Launch configuration:", params
        launcher = boto.ec2.autoscale.launchconfig.LaunchConfiguration(autoscale, **params)
        print autoscale.create_launch_configuration(launcher)
    else:
        print '=> Launch configuration already exists, skipping'

    group = autoscale.get_all_groups(names=[ definition['auto-scaling-group'] ])
    if len(group) == 0:
        if 'load-balancers' in definition:
            lb = definition['load-balancers']
            if not isinstance(lb, list):
                lb = [ lb ]
            print '* Checking that load balancers exist:', lb
            hc2002.resource.load_balancer.list(lb)

        params = xl.translate(auto_scaling_group_mapping, definition)
        print "Auto scaling groups:", params
        group = boto.ec2.autoscale.group.AutoScalingGroup(autoscale, **params)
        print autoscale.create_auto_scaling_group(group)
    else:
        print '=> Auto-scaling group already exists, skipping'

    # TODO: Handle load balancers
    # TODO: Handle updates to both launch configuration and group

    if 'schedule' in definition:
        for name, schedule in definition['schedule'].iteritems():
            params = xl.translate(scheduled_auto_scaling_action, schedule)
            params['AutoScalingGroupName'] = definition['auto-scaling-group']
            params['ScheduledActionName'] = name

            response = autoscale.make_request('PutScheduledUpdateGroupAction', params)
            if response.status != 200:
                print 'Failed to schedule %s scaling action' % name
                print response.read()

def parse_args(args=None, namespace=None):
    parser = argparse.ArgumentParser(fromfile_prefix_chars='@')

    parser.add_argument('-O', '--aws-access-key', metavar='<key>',
            help='AWS Access Key ID. Defaults to AWS_ACCESS_KEY environment '
            'variable, if set.')
    parser.add_argument('-W', '--aws-secret-key', metavar='<secret>',
            help='AWS Secret Access Key. Defaults to AWS_SECRET_KEY '
            'environment variable, if set.')

    region_required = not hasattr(namespace, 'region') or not namespace.region
    parser.add_argument('--region', metavar='<region>',
            required=region_required, help='AWS EC2 Region. Defaults to '
            'EC2_REGION environment variable, if set.')

    parser.add_argument('--instance-path', metavar='<path>', action='append',
            help='Append path to list of instance definition search paths. If '
            'no path is specified on the command line definitions are loaded '
            'from the current directory.')
    parser.add_argument('--puppet-path', metavar='<path>', action='append',
            help='Append path to list of puppet manifest search paths. If no '
            'path is specified on the command line puppet manifests are '
            'loaded from the current directory.')

    actions = parser.add_subparsers(title='actions')

    bootstrap = actions.add_parser('bootstrap', description='Set up SSH key '
            'and default security group.')
    bootstrap.add_argument('-k', '--key', default='hc2000', help='Name of the '
            'key pair to be created.')
    bootstrap.add_argument('--security-group', default='hc2000-ssh',
            help='Name of the default security group that will be created. '
            'This group allows incoming SSH connections, by default.')
    bootstrap.add_argument('path', default='', nargs='?', help='Path to '
            'populate with default setup. Defaults to current directory')
    bootstrap.set_defaults(actor=BootstrapActor())

    launch = actions.add_parser('launch', argument_default=argparse.SUPPRESS,
            description='Launch isolated instances, spot instances and '
            'auto-scaling groups.')
    launch.add_argument('--client-token', metavar='<token>',
            help='User-defined token identifying the request. Use to ensure '
            'idempotent requests.')
    launch.add_argument('-n', '--instance-count', metavar='<count>',
            help='Number of instances to launch. Overrides \'count\' '
            'attribute in instance definition.')
    launch.add_argument('-s', '--subnet', metavar='<subnet>',
            help='Subnet identifier for started instances. Overrides '
            '\'subnet\' attribute in instance definition.')
    launch.add_argument('-z', '--availability-zone', metavar='<zone>',
            help='Availability zone for started instances. Overrides '
            '\'availability-zone\' attribute in instance definition.')
    launch.add_argument('instance', help='Path to instance definition file.')
    launch.set_defaults(actor=launch_action)

    create_role = actions.add_parser('create-role',
            description='Creates an IAM role with specified policies, and an '
            'associated instance-profile, that can be used when launching '
            'instances.')
    create_role.add_argument('role', help='Path to role definition file.')
    create_role.set_defaults(actor=create_role_action)

    return parser.parse_args(args, namespace)

def set_default_config(config):
    if config.instance_path is None:
        config.instance_path = [ '.' ]
    if config.puppet_path is None:
        config.puppet_path = [ '.' ]

if __name__ == '__main__':
    config = parse_args(namespace=hc2002.config)
    set_default_config(config)
    config.actor(config)
